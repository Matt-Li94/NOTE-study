# 一些常用的重要概念
## 1.迁移学习
**迁移学习理解：一般用在已有一个预训练好的模型，并将其应用到现有任务上的过程**


源领域和目标领域的任务不同，但数据分布相似。通过在源领域上训练模型，然后在目标领域上微调。通俗讲就是训练在一个数据集上，然而应用是在另外一个数据集上，一般有以下两种方式

（1） 基于特征的方式：将预训练模型的输出或者是中间隐藏层的输出作为 特征直接加入到目标任务的学习模型中．目标任务的学习模型可以是一般的浅 层分类器（比如全连接层等）或一个新的神经网络模型．
（2） 精调的方式：在目标任务上复用预训练模型的部分组件，并对其参数 进行精调（Fine-Tuning）．

微调的策略（实验中体现）
全模型微调：对整个模型进行微调，适用于源任务和目标任务相似的情况。
部分微调：只微调模型的最后几层，适用于源任务和目标任务差异较大的情况。
冻结层：在微调过程中，可以选择冻结某些层的权重，只训练特定的层，以保持预训练模型的特征提取能力。

eg：b站小土堆使用的vgg16篇章，直接修改vgg16中的一些网络层来适配自己的分类任务
![alt text](https://i-blog.csdnimg.cn/blog_migrate/ce9540e5341406eeefe0de35e410807a.png)